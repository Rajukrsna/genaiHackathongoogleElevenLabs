# Edge Cases Implementation Summary

This document describes the edge cases implemented based on the Figma design specifications for VocalAid GTM.

## Overview

The implementation follows the Figma documentation which specifies that edge cases should be handled through a robust communication failure detection system rather than pre-fed scripted responses. The AI dynamically generates repair prompts that vary each time to demonstrate genuine AI capabilities.

## Implemented Edge Cases

### 1. Intro Message for New Callers ✅

**Location**: [src/components/call/MessageCards.tsx](src/components/call/MessageCards.tsx)

**Description**: When a call is accepted, an introductory message is automatically displayed to inform the caller about the assistive communication app.

**Default Message**:
> "Hello. I'm using an assistive communication app to respond. Please speak one sentence at a time and pause so I can reply accurately. Thank you for your patience."

**Implementation**:
- Added `IntroMessage` component that displays on call start
- Automatically added to message history when call is accepted
- Can be customized with different messages if needed

---

### 2. No Speech Detected ✅

**Location**: [server/controllers/aiController.ts](server/controllers/aiController.ts)

**Description**: Detects when the system receives silence, very short audio, or meaningless sounds.

**Detection Logic**:
- AI analyzes speech input quality using Gemini AI
- Classifies input as `no_speech` when:
  - Empty or very short transcription
  - Meaningless sounds detected
  - Confidence score > 0.6

**Repair Prompts** (dynamically generated):
- "I'm sorry, I couldn't hear you. Could you please speak a bit louder?"
- "Hello? I'm having trouble hearing you right now. Can you try again?"

**UI Display**:
- Shows "No Speech Detected" as the title in IntentDetection component
- Displays 2 repair prompt options (no regenerate button)

---

### 3. Background Noise / Multiple Voices Detection ✅

**Location**: [server/controllers/aiController.ts](server/controllers/aiController.ts)

**Description**: Identifies when heavy background noise or multiple overlapping voices are present.

**Detection Logic**:
- AI analyzes transcription for signs of noise or gibberish
- Classifies as:
  - `noise`: Heavy background noise evident in transcription
  - `multiple_voices`: Evidence of multiple speakers
  - `gibberish`: Incoherent, fragmented, or nonsensical words

**Example Detected Inputs**:
- "where are you yes yes near lift no not lift main gate hello can you hear"
- Multiple fragmented or overlapping phrases

**Repair Prompts** (dynamically generated for noise):
- "There's quite a bit of background noise. Could you move to a quieter spot?"
- "I'm having difficulty hearing you clearly due to the noise around you. Is there a quieter place you could speak from?"

**Repair Prompts** (for multiple voices):
- "I'm hearing multiple voices. Could one person speak at a time, please?"
- "It sounds like there are several people talking. Could you speak individually, please?"

**UI Display**:
- Shows "Background Noise Detected" or "Unclear Speech Detected"
- Displays repair prompt options specific to the issue

---

### 4. Undo Functionality ✅

**Location**: 
- [src/components/call/MessageCards.tsx](src/components/call/MessageCards.tsx) - UI Component
- [src/pages/CallPage.tsx](src/pages/CallPage.tsx) - Logic

**Description**: Allows users to undo their last response if they accidentally selected the wrong option.

**Features**:
- Undo button (↻ icon) appears only on the most recent outgoing message
- When clicked:
  - Removes the last outgoing message from history
  - Restores conversation context (removes "You: " entry)
  - Automatically regenerates suggestions for the last incoming message
  
**UI Implementation**:
- Small undo icon appears in the bottom-right corner of the last outgoing message
- Hover effect for better UX
- Only shows on the most recent message to prevent confusion

---

## Architecture Details

### Three-Layer Mental Model

As specified in the Figma documentation:

1. **Input Quality Check** (Layer 1)
   - Analyzes: Is this speech usable?
   - Uses Gemini AI to assess confidence and quality
   - Determines if input should proceed to intent extraction

2. **Intent Extraction** (Layer 2)
   - Analyzes: What is the user asking?
   - Only triggered if input quality is good
   - Generates contextual reply options

3. **Response Options** (Layer 3)
   - Provides either:
     - Normal intent-based replies (for good quality input)
     - Repair prompts (for communication failures)

### Repair Prompts vs. Pre-fed Responses

**Key Principle**: Repair prompts are NOT pre-fed intent responses. They belong to a separate failure-handling layer.

**Implementation**:
- Repair prompts are dynamically generated by AI each time
- Vary slightly in tone and phrasing to demonstrate AI capabilities
- Context-aware based on the specific failure type
- Two variations provided per failure type (one direct, one apologetic)

### Communication Failure Response Format

```typescript
interface ProcessIntentResponse {
  originalText: string;
  replies: string[];
  isCommunicationFailure?: boolean;  // true for edge cases
  failureType?: 'no_speech' | 'noise' | 'gibberish' | 'multiple_voices';
  failureReason?: string;  // AI-generated explanation
}
```

---

## User Experience Flow

### Normal Flow
1. Caller speaks clearly
2. System transcribes speech
3. AI detects intent
4. Shows "Intent Detected" with reply options
5. User selects reply (can undo if wrong)

### Edge Case Flow - No Speech
1. System detects silence/no clear speech
2. Quality check identifies `no_speech`
3. Shows "No Speech Detected"
4. Displays repair prompts asking caller to speak louder
5. User selects appropriate repair prompt

### Edge Case Flow - Background Noise
1. Caller speaks in noisy environment
2. Transcription contains fragmented/garbled text
3. Quality check identifies `noise` or `multiple_voices`
4. Shows "Background Noise Detected" / "Unclear Speech Detected"
5. Displays repair prompts asking for quieter location
6. User selects appropriate repair prompt

---

## Testing Recommendations

### Test Scenarios

1. **New Call Start**
   - Verify intro message appears automatically
   - Check message format and styling

2. **Clear Speech**
   - Normal conversation flow
   - Verify "Intent Detected" appears
   - Check regenerate functionality

3. **No Speech**
   - Submit very short audio
   - Verify "No Speech Detected" title
   - Check repair prompts are varied

4. **Background Noise**
   - Submit audio with background noise (if possible)
   - Or test with fragmented text: "yes no maybe where hello"
   - Verify appropriate detection and prompts

5. **Undo Functionality**
   - Select a response
   - Verify undo button appears
   - Click undo and verify:
     - Message removed
     - Suggestions regenerated
     - Context properly restored

---

## Configuration

### AI Model Settings

**Speech-to-Text**: ElevenLabs Scribe v1
**Intent Processing**: Google Gemini 2.5 Flash
**Text-to-Speech**: ElevenLabs Multilingual v2

### Quality Check Thresholds

- Confidence threshold for failure detection: **0.6**
- Minimum audio size for processing: **1000 bytes**
- Silence duration before processing: **1500ms**

---

## Future Enhancements

Potential improvements based on usage data:

1. **Adaptive Thresholds**: Adjust confidence thresholds based on user's environment
2. **Custom Repair Prompts**: Allow users to set preferred repair messages
3. **Failure Statistics**: Track most common failure types for optimization
4. **Multi-language Support**: Extend edge case handling to multiple languages
5. **Environmental Detection**: Proactively warn about noisy environments

---

## File Changes Summary

### New Components
- `IntroMessage` - Displays intro message for new callers

### Modified Components
- `IntentDetection` - Added edge case title handling
- `OutgoingCard` - Added undo button functionality
- `MessageCards` - Extended for new message types

### Backend Changes
- `aiController.ts`:
  - Added `generateRepairPrompts()` function
  - Added quality check in `processIntent()`
  - Enhanced transcription text extraction

### Frontend Changes
- `CallPage.tsx`:
  - Added intro message on call start
  - Implemented undo functionality
  - Added edge case state management
  - Enhanced message rendering

### API Changes
- `callService.ts`:
  - Updated `processIntent()` signature and return type
  - Added `ProcessIntentResponse` interface

---

## Documentation References

- **Figma Design**: [Vocal Aid GTM - Edge Cases](https://www.figma.com/design/5kKgs7NGERHfrH3Wn6rENZ/Vocal-Aid-GTM?node-id=54-741)
- **Edge Case Guidelines**: Node ID 54:771 in Figma
- **Implementation Notes**: This file

---

*Implementation completed on: December 24, 2025*
*Based on Figma specifications: Vocal Aid GTM / Edge Cases*
